{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesukjang/Income_Prediction/blob/main/Kesha_2nd_Notebook_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRg8iC99hXv-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "#colab imports\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#tensorflow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import plot_model, to_categorical, Sequence\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "JTB_eoUPhe5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb7348c-b8a4-48ec-e7b8-7c1bec659407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#replace these paths with the paths of your \n",
        "val_image_directory = '/content/gdrive/MyDrive/207_final_project/Dataset/Validate'\n",
        "train_image_directory = '/content/gdrive/MyDrive/207_final_project/Dataset/Train'\n",
        "test_image_directory = '/content/gdrive/MyDrive/207_final_project/Dataset/Test'\n",
        "directory_path = '/content/gdrive/MyDrive/207_final_project'"
      ],
      "metadata": {
        "id": "cG5GVjqL_CmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paths(directory):\n",
        "  all_path = []\n",
        "  idc_image_path = []\n",
        "  idc_image_label = []\n",
        "\n",
        "  for dir, subdir, files in os.walk(directory):\n",
        "    path = dir + \"/\"\n",
        "    all_path.append(path)\n",
        "\n",
        "  for i in range(len(all_path)):\n",
        "    for file in os.listdir(all_path[i]):\n",
        "      test = file\n",
        "      path = all_path[i] + test\n",
        "      if path.lower().endswith('.png'):\n",
        "        idc_image_path.append(path)\n",
        "\n",
        "  for i in range(len(idc_image_path)):\n",
        "    split_test = idc_image_path[i]\n",
        "    split_path = split_test.split(\"/\")\n",
        "    directory_name = split_path[6]\n",
        "    idc_image_label.append('class_' + split_path[7])\n",
        "  return idc_image_path, idc_image_label, directory_name"
      ],
      "metadata": {
        "id": "qXWIfII8Gmj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, train_labels, train_dir = get_paths(train_image_directory)\n",
        "val_paths, val_labels, val_dir = get_paths(val_image_directory)\n",
        "test_paths, test_labels, test_dir = get_paths(test_image_directory)"
      ],
      "metadata": {
        "id": "ZxEYmR4q2n3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_paths), len(train_labels))\n",
        "print(len(test_paths), len(test_labels))\n",
        "print(len(val_paths), len(val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUL7rCOv3CgX",
        "outputId": "1ae2a62b-fa91-4f0a-dbd3-0483892f40e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 800\n",
            "200 200\n",
            "200 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframes(idc_image_path, idc_image_label, directory_name):\n",
        "  same_name = directory_name.lower() + '_'\n",
        "  #creating the dataframes that we will be passing to our generators\n",
        "  idc_data_cleaned = {'path': idc_image_path,\n",
        "            'label': idc_image_label}\n",
        "\n",
        "  idc_df = pd.DataFrame(idc_data_cleaned)\n",
        "  df = idc_df.sample(frac = 1)\n",
        "  print(df)\n",
        "\n",
        "  csv_path = directory_path\n",
        "  csv_file = df.to_csv(csv_path + '/' + same_name + 'idc_dataframe.csv')\n",
        "  return csv_file"
      ],
      "metadata": {
        "id": "NOLoDO1GMXTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "train_generator = pd.read_csv(train_dataframe)\n",
        "\n",
        "test_dataframe = create_dataframes(test_paths, test_labels, test_dir)\n",
        "test_generator = pd.read_csv(test_dataframe)\n",
        "\n",
        "val_dataframe = create_dataframes(val_paths, val_labels, val_dir)\n",
        "val_generator = pd.read_csv(val_dataframe)"
      ],
      "metadata": {
        "id": "Olnml8vUhhce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator()\n",
        "\n",
        "train_data_generator = data_generator.flow_from_dataframe(\n",
        "    train_generator,\n",
        "    directory = None,\n",
        "    x_col =  'path',\n",
        "    y_col =  'label',\n",
        "    weight_col=None,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    #readjust the target size based on max size of images\n",
        "    target_size=(50, 50),\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    # validate_filenames=True\n",
        ")\n",
        "\n",
        "validation_data_generator = data_generator.flow_from_dataframe(\n",
        "    val_generator,\n",
        "    directory = None,\n",
        "    x_col =  'path',\n",
        "    y_col =  'label',\n",
        "    weight_col=None,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    #readjust the target size based on max size of images\n",
        "    target_size=(50, 50),\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    # validate_filenames=True\n",
        ")\n",
        "\n",
        "# test_data_generator = "
      ],
      "metadata": {
        "id": "xhocLsGWhjwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297f35f6-4a46-4754-ac19-e0a9b24c2461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 50\n",
        "img_width = 50\n",
        "img_channel = 1"
      ],
      "metadata": {
        "id": "rktiLcaIhlpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_doc_id_model():\n",
        "  return tf.keras.Sequential([\n",
        "                           keras.layers.Conv2D(input_shape = (img_height, img_width, img_channel), \n",
        "                                               filters=32, \n",
        "                                               kernel_size=(3, 3),\n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                           \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                                  strides=(2, 2)),\n",
        "                           \n",
        "                           keras.layers.Conv2D(filters=64, \n",
        "                                               kernel_size=(3, 3), \n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                              \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                                  strides=(2, 2)),\n",
        "                          \n",
        "                           keras.layers.Conv2D(filters=128, \n",
        "                                               kernel_size=(3, 3), \n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                          \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2), \n",
        "                                                  strides=(2, 2)),\n",
        "                           \n",
        "                           keras.layers.Flatten(),\n",
        "                           \n",
        "                           keras.layers.Dense(units = 256, \n",
        "                                              activation = 'relu'),\n",
        "                           \n",
        "                          #  keras.layers.Dense(units = 512, \n",
        "                          #                     activation = 'relu'),\n",
        "                           \n",
        "                           keras.layers.Dense(units = 2, \n",
        "                                              activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "OWAOrPUfhqAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_doc_id_model()\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.001), \n",
        "                    loss=keras.losses.categorical_crossentropy, \n",
        "                    metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ug0UqwlKhqup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92882d7-3d4c-4942-c712-79b24beb911e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 50, 50, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 25, 25, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1179904   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,273,090\n",
            "Trainable params: 1,273,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc_early_stopping = EarlyStopping(monitor = 'val_acc', \n",
        "                                       patience = 5, \n",
        "                                       verbose = 1,\n",
        "                                       mode = 'auto')"
      ],
      "metadata": {
        "id": "J9j8hJiJhxC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train_data_generator,\n",
        "                 epochs=7,\n",
        "                #  callbacks=[val_acc_early_stopping],\n",
        "                 validation_data = validation_data_generator\n",
        "                 )"
      ],
      "metadata": {
        "id": "4Bx5SvT7h0OF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53b0980-23f9-4658-d5b0-c5d0b47f2316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "25/25 [==============================] - 734s 29s/step - loss: 10.1173 - accuracy: 0.5088 - val_loss: 0.7157 - val_accuracy: 0.5050\n",
            "Epoch 2/7\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.6588 - accuracy: 0.6037 - val_loss: 0.6701 - val_accuracy: 0.5300\n",
            "Epoch 3/7\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.6439 - accuracy: 0.6037 - val_loss: 0.6532 - val_accuracy: 0.6000\n",
            "Epoch 4/7\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 0.5793 - accuracy: 0.7025 - val_loss: 0.5879 - val_accuracy: 0.6950\n",
            "Epoch 5/7\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.6227 - accuracy: 0.6413 - val_loss: 0.5993 - val_accuracy: 0.6950\n",
            "Epoch 6/7\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.5198 - accuracy: 0.7412 - val_loss: 0.5778 - val_accuracy: 0.7200\n",
            "Epoch 7/7\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.4877 - accuracy: 0.7600 - val_loss: 0.5763 - val_accuracy: 0.7250\n"
          ]
        }
      ]
    }
  ]
}
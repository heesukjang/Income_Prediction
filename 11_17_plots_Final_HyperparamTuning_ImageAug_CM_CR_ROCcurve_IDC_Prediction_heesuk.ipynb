{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesukjang/Income_Prediction/blob/main/11_17_plots_Final_HyperparamTuning_ImageAug_CM_CR_ROCcurve_IDC_Prediction_heesuk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FALL 2022<br>\n",
        "W207 Applied Machine Learning<br>\n",
        "Heesuk Jang\n",
        " \n",
        "\n",
        "**XGBoost:** an optimized version of Gradient Boosting / much more evolved version of Random Forest in terms of speed and accuracy\n",
        "\n",
        "#Predicting IDC with Breast Histopathology Images using CNN\n",
        "\n"
      ],
      "metadata": {
        "id": "5DebDWCL0KeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SRkZHKoWswZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33339e14-86e5-4d3d-babc-77ba09a18694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import *                            # confusion_matrix, log_loss, accuracy_score\n",
        "from sklearn.model_selection import *                    # train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import *  \n",
        "# from sklearn.ensemble import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.linear_model import *                       # LinearRegression\n",
        "from sklearn.discriminant_analysis import *\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import RandomFlip, RandomZoom, RandomRotation, Conv2D, MaxPooling2D, AveragePooling2D, Input, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad, RMSprop\n",
        "from keras.layers import ReLU, LeakyReLU\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import ReLU, LeakyReLU\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, auc\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "tf.get_logger().setLevel('INFO')\n",
        "\n",
        "import cv2 as cv\n",
        "import skimage.io as io\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Optuna and Version Check"
      ],
      "metadata": {
        "id": "2NlEwp6jmZsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --quiet optuna\n",
        "# import optuna\n",
        "# optuna.__version__"
      ],
      "metadata": {
        "id": "vbF2pFtlbJaH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "# !pip install xgboost\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "XmhJR4rTcSlm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73269dd-2f3e-4a3a-acf5-be3ef5a0750e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 135 kB 36.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 55.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enabling and testing the GPU"
      ],
      "metadata": {
        "id": "2JC1sfIYmRuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   raise SystemError('GPU device not found')\n",
        "# print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "lpo1_3kNlzoo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enabling and testing the TPU"
      ],
      "metadata": {
        "id": "s3LsW0cGnF8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU"
      ],
      "metadata": {
        "id": "Xqgm8yAcmT7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip gdrive/MyDrive/Kaggle/CNN_IDC/Dataset.zip\n",
        "\n",
        "#replace these paths with the paths of your \n",
        "val_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Validate'\n",
        "train_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train'\n",
        "test_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Test'\n",
        "directory_path = '/content/gdrive/MyDrive/Kaggle/CNN_IDC'"
      ],
      "metadata": {
        "id": "uyWJuOkZuCVl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paths(directory):\n",
        "  all_path = []\n",
        "  idc_image_path = []\n",
        "  idc_image_label = []\n",
        "\n",
        "  for dir, subdir, files in os.walk(directory):\n",
        "    path = dir + \"/\"\n",
        "    all_path.append(path)\n",
        "\n",
        "  for i in range(len(all_path)):\n",
        "    for file in os.listdir(all_path[i]):\n",
        "      test = file\n",
        "      path = all_path[i] + test\n",
        "      if path.lower().endswith('.png'):\n",
        "        idc_image_path.append(path)\n",
        "\n",
        "  for i in range(len(idc_image_path)):\n",
        "    split_test = idc_image_path[i]\n",
        "    split_path = split_test.split(\"/\")\n",
        "    directory_name = split_path[7]\n",
        "    idc_image_label.append('class_' + split_path[8])\n",
        "  return idc_image_path, idc_image_label, directory_name"
      ],
      "metadata": {
        "id": "N892xh1IM4q7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, train_labels, train_dir = get_paths(train_image_directory)\n",
        "val_paths, val_labels, val_dir = get_paths(val_image_directory)\n",
        "test_paths, test_labels, test_dir = get_paths(test_image_directory)"
      ],
      "metadata": {
        "id": "SJ6Cl4wtmxjO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[:5])\n",
        "print(train_labels[-5:])\n",
        "\n",
        "print(len(train_paths), len(train_labels))\n",
        "print(len(test_paths), len(test_labels))\n",
        "print(len(val_paths), len(val_labels))"
      ],
      "metadata": {
        "id": "NIf9ETAsmxa2",
        "outputId": "7f1b4e60-60bf-4d80-be16-eed19b28702f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['class_0', 'class_0', 'class_0', 'class_0', 'class_0']\n",
            "['class_1', 'class_1', 'class_1', 'class_1', 'class_1']\n",
            "800 800\n",
            "200 200\n",
            "200 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_paths[:2])\n",
        "print(train_labels[:10])\n",
        "print(train_dir)"
      ],
      "metadata": {
        "id": "uCJzEwS8mxSR",
        "outputId": "202fa1ae-8a3f-4769-b587-1c1ad901aefa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12880_idx5_x451_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9345_idx5_x2001_y2001_class0.png']\n",
            "['class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0']\n",
            "Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframes(idc_image_path, idc_image_label, directory_name):\n",
        "  same_name = directory_name.lower() + '_'\n",
        "  #creating the dataframes that we will be passing to our generators\n",
        "  idc_data_cleaned = {'path': idc_image_path,\n",
        "            'label': idc_image_label}\n",
        "  idc_df = pd.DataFrame(idc_data_cleaned)\n",
        "  idc_df['label_int'] = idc_df['label'].str.split(\"_\", expand=True)[1]    # Added a new column 'label_int'\n",
        "  df = idc_df.sample(frac = 1)\n",
        "  print(df)\n",
        "  csv_path = directory_path\n",
        "  csv_file = df.to_csv(csv_path + '/' + same_name + 'idc_dataframe.csv')\n",
        "  csv_file_path = csv_path + '/' + same_name + 'idc_dataframe.csv'\n",
        "  return csv_file_path"
      ],
      "metadata": {
        "id": "_WU9qt2RmxHZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "print('type(train_dataframe): ',type(train_dataframe))\n",
        "train_dataframe"
      ],
      "metadata": {
        "id": "MJxUgm39NeU7",
        "outputId": "851e71dd-bd03-411f-cf75-2d8f12cfff5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  path    label label_int\n",
            "534  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "598  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "258  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "505  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "131  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "..                                                 ...      ...       ...\n",
            "480  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "374  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "718  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "496  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "657  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "\n",
            "[800 rows x 3 columns]\n",
            "type(train_dataframe):  <class 'str'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Kaggle/CNN_IDC/train_idc_dataframe.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "train_generator = pd.read_csv(train_dataframe)\n",
        "\n",
        "test_dataframe = create_dataframes(test_paths, test_labels, test_dir)\n",
        "test_generator = pd.read_csv(test_dataframe)\n",
        "\n",
        "val_dataframe = create_dataframes(val_paths, val_labels, val_dir)\n",
        "val_generator = pd.read_csv(val_dataframe)"
      ],
      "metadata": {
        "id": "hnDu_3N4mw1G",
        "outputId": "4bca811f-7554-4f7a-e8ad-9d6c65f321d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  path    label label_int\n",
            "542  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "706  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "729  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "241  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "205  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "..                                                 ...      ...       ...\n",
            "425  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "208  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "191  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "128  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "225  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "\n",
            "[800 rows x 3 columns]\n",
            "                                                  path    label label_int\n",
            "6    /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "117  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "123  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "34   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "48   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "..                                                 ...      ...       ...\n",
            "180  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "171  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "26   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "192  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "89   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "\n",
            "[200 rows x 3 columns]\n",
            "                                                  path    label label_int\n",
            "154  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "152  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "115  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "166  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "86   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "..                                                 ...      ...       ...\n",
            "43   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "189  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "31   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "7    /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0         0\n",
            "169  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1         1\n",
            "\n",
            "[200 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # import tqdm\n",
        "\n",
        "# Apply gray scale to all images, flatten and store array / shape in new columns\n",
        "def get_img_arrays(df,):\n",
        "    # read each image array from corresponding path as grayscale and flatten the image array\n",
        "    df['img_array'] = df.progress_apply(lambda x : io.imread(x['path'],as_gray=True).flatten(),axis=1) # make sure to specify axis = 1\n",
        "    # get the shape of each image array and store it in the dataframe\n",
        "    df['array_shape'] = df.progress_apply(lambda x : x['img_array'].shape[0],axis=1) # make sure to specify axis = 1\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "nkWYjNvnHrrn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # import tqdm\n",
        "tqdm.pandas() # initialize tqdm for pandas\n",
        "\n",
        "# # tqdm is a library that enables you to visualize the progress of a for loop by displaying a configurable progress bar\n",
        "\n",
        "train_generator = get_img_arrays(df = train_generator)\n",
        "val_generator = get_img_arrays(df = val_generator)\n",
        "test_generator = get_img_arrays(df = test_generator)"
      ],
      "metadata": {
        "id": "d9iPVxRZHreQ",
        "outputId": "3a6a281c-d899-47a6-e6f6-0475bfb084f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 670/800 [04:40<00:54,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-16d6a4c8c26d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# # tqdm is a library that enables you to visualize the progress of a for loop by displaying a configurable progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d1f6dadd4eb3>\u001b[0m in \u001b[0;36mget_img_arrays\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_img_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# read each image array from corresponding path as grayscale and flatten the image array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_array'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make sure to specify axis = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# get the shape of each image array and store it in the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'array_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make sure to specify axis = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d1f6dadd4eb3>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_img_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# read each image array from corresponding path as grayscale and flatten the image array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_array'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make sure to specify axis = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# get the shape of each image array and store it in the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'array_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make sure to specify axis = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                (plugin, kind))\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_read_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmodename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODENAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36msearch_read_format\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;31m# Select the first that can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_formats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mcan_read\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mformat\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mread\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcan_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36m_can_read\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPEN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugin_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstbytes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mfirstbytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \"\"\"\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_first_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_read_first_bytes\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# Read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_n_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0;31m# Set back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mread_n_bytes\u001b[0;34m(f, N)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0mextra_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextra_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_generator.array_shape.value_counts())\n",
        "# print(val_generator.array_shape.value_counts())\n",
        "# print(test_generator.array_shape.value_counts())"
      ],
      "metadata": {
        "id": "wAv7RXmVQX4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop these images as they add unnecessary noise to our model\n",
        "train_weird_imgs = train_generator[train_generator['array_shape'] != 2500]\n",
        "val_weird_imgs = val_generator[val_generator['array_shape'] != 2500]\n",
        "test_weird_imgs = test_generator[test_generator['array_shape'] != 2500]\n",
        "\n",
        "\n",
        "weird_imgs = train_weird_imgs.append(val_weird_imgs)\n",
        "weird_imgs = weird_imgs.append(test_weird_imgs)\n",
        "weird_imgs['dataset'] = weird_imgs['path'].str.split('/', expand=True)[7]\n",
        "weird_imgs.reset_index(drop=True)\n",
        "\n",
        "train_generator.drop(train_weird_imgs.index,inplace=True)\n",
        "val_generator.drop(val_weird_imgs.index,inplace=True)\n",
        "test_generator.drop(test_weird_imgs.index,inplace=True)\n",
        "\n",
        "# print(len(weird_imgs))\n",
        "# print(len(train_generator))\n",
        "# print(len(val_generator))\n",
        "# print(len(test_generator))\n",
        "# print(train_generator.columns)\n",
        "# val_generator.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "gpOS9_alHrTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import skimage.io as io\n",
        "\n",
        "def display_images(subclass):\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(20,8))\n",
        "  for idx, ax in enumerate(axes.flat):\n",
        "    image_wo_path = os.path.basename(subclass.path[idx])\n",
        "    # print(image_wo_path)\n",
        "    subtitle = 'Class ' + image_wo_path.rsplit('.')[0][-1] + ': ' + subclass.dataset[idx]\n",
        "    img = io.imread(subclass.path[idx])\n",
        "    ax.imshow(img)\n",
        "    # ax.axis('off')\n",
        "    ax.set_title(subtitle, size=14)   \n",
        "  fig.tight_layout() \n",
        "  plt.show() \n",
        "\n",
        "print()\n",
        "display_images(weird_imgs.reset_index(drop=True))"
      ],
      "metadata": {
        "id": "x9euSsBNHrIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing data using ImageDataGenerator"
      ],
      "metadata": {
        "id": "iHdf3Jd0ipmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://faroit.com/keras-docs/0.3.3/preprocessing/image/\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "def data_generator():\n",
        "\n",
        "  with_aug_datagen = ImageDataGenerator(\n",
        "      featurewise_center = True,                     # transforms the images to 0 mean\n",
        "      featurewise_std_normalization = True,          # divide inputs by std of the dataset\n",
        "      # zca_epsilon=1e-06,\n",
        "      rotation_range=30,                      # randomly rotate image by 10 degrees\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      brightness_range=[0.4, 1.5],\n",
        "      shear_range=0.2,                        # distort image along an axis mostly to create or recify the perception angles     \n",
        "      zoom_range=0.2,                         # zomming image: zoom_range > 1 => zoom out, zoom_range < 1 => zoom in                  \n",
        "      fill_mode='nearest',                    # when the image is rotated, some pixels will move outside the image and leave an empty area that needs to be filled in, 'nearest': simply replace the empty area with the nearest spectral values.\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True)\n",
        "      \n",
        "  without_aug_datagen = ImageDataGenerator()\n",
        "  \n",
        "# =================================================================\n",
        "  # if with_augmented_images:\n",
        "  train_data_generator = with_aug_datagen.flow_from_dataframe(\n",
        "        train_generator,\n",
        "        directory = None,\n",
        "        x_col =  'path',\n",
        "        y_col =  'label',\n",
        "        weight_col=None,\n",
        "        target_size=(50,50),\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=1234\n",
        "        # validate_filenames=True\n",
        "    )\n",
        "  # else:\n",
        "  #   train_data_generator = without_aug_datagen.flow_from_dataframe(\n",
        "  #       train_generator,\n",
        "  #       directory = None,\n",
        "  #       x_col =  'path',\n",
        "  #       y_col =  'label',\n",
        "  #       weight_col=None,\n",
        "  #       target_size=(50,50),\n",
        "  #       color_mode=\"grayscale\",\n",
        "  #       class_mode=\"categorical\",\n",
        "  #       batch_size=32,\n",
        "  #       shuffle=True,\n",
        "  #       seed=1234\n",
        "  #       # validate_filenames=True\n",
        "  #   )\n",
        "\n",
        "  validation_data_generator = without_aug_datagen.flow_from_dataframe(\n",
        "      val_generator,\n",
        "      directory = None,\n",
        "      x_col =  'path',\n",
        "      y_col =  'label',\n",
        "      weight_col=None,\n",
        "      # target_size=(hp_target_size, hp_target_size),\n",
        "      target_size=(50,50),\n",
        "      color_mode=\"grayscale\",\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=32,\n",
        "      shuffle=True,\n",
        "      seed=1234\n",
        "      # validate_filenames=True\n",
        "  )\n",
        "\n",
        "  test_data_generator = without_aug_datagen.flow_from_dataframe(\n",
        "      test_generator,\n",
        "      directory = None,\n",
        "      x_col =  'path',\n",
        "      y_col =  'label',\n",
        "      weight_col=None,\n",
        "      target_size=(50,50),\n",
        "      color_mode=\"grayscale\",\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=32,\n",
        "      shuffle=True,              # Kesha set to shuffle=True but we don't want to shuffle our testing data around, which it does so by default\n",
        "      seed=1234\n",
        "      # validate_filenames=True\n",
        "  )\n",
        "  return train_data_generator, validation_data_generator, test_data_generator\n",
        "\n",
        "# train_data_generator, validation_data_generator, test_data_generator = data_generator(with_augmented_images=True)\n",
        "train_data_generator, validation_data_generator, test_data_generator = data_generator()"
      ],
      "metadata": {
        "id": "9_IibHAwxE6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build CNN Model and Hyperparameter Tuning\n",
        "- **ReduceLROnPlateau**: A scheduling technique that monitors a particular quantity and decays the learning rate when the quantity is stop improving.\n",
        "- **ModelCheckpoint**: A sch\n",
        "- **BatchNormalization**: A feature that we add between the layers of neural network and it continuously takes the output from the previous layer and normalizes it before sending it to the next layer thereby helping stablizing the NN"
      ],
      "metadata": {
        "id": "I19l1YOYsfOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# img_height = 50\n",
        "# img_width = 50\n",
        "# img_channel = 1\n",
        "# input_shape = (img_height, img_width, img_channel)"
      ],
      "metadata": {
        "id": "OQcHdDdYJnol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import ReLU, LeakyReLU\n",
        "# https://keras.io/guides/keras_tuner/getting_started/\n",
        "\n",
        "def build_cnn(hp): \n",
        "  # train_data_generator, validation_data_generator, test_data_generator = data_generator(hp)\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.random.set_seed(0)\n",
        "\n",
        "# Define ranges of hyperparam values \n",
        "  # hp_img_size = hp.get('hp_target_size')\n",
        "  # hp_img_size = hp.Int('img_size', 50,96,120)\n",
        "  # hp_img_size = hp.Int('img_size', 50,96)\n",
        "  hp_kernel_size = hp.Int('kernel_size', min_value=2, max_value=5, step=1)\n",
        "  hp_strides = hp.Int('strides', min_value=1, max_value=2, step=1)\n",
        "  hp_pool_size = hp.Int('pool_size', min_value=2, max_value=3, step=1)\n",
        "  hp_activation = hp.Choice('activation', values=['tanh', 'relu', 'softmax', 'sigmoid', 'leaky_relu', 'elu', 'gelu','selu','swish'], default='relu')\n",
        "  hp_optimizer = hp.Choice('optimizer', values=['adadelta', 'adagrad', 'adam', 'rmsprop', 'sgd'], default='adam')\n",
        "  hp_filters_1 = hp.Int('filters_1', min_value=8, max_value=64, step=8)\n",
        "  hp_filters_2 = hp.Int('filters_2', min_value=8, max_value=128, step=16)\n",
        "  hp_filters_3 = hp.Int('filters_3', min_value=32, max_value=128, step=16)\n",
        "  hp_dense = hp.Int('dense_units', min_value=32, max_value=512, step=34)\n",
        "  hp_learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-2)\n",
        "  hp_dropout_1 = hp.Float('dropout_rate_1', min_value=0.1, max_value=0.5, default=0.1, step=0.1)\n",
        "  hp_dropout_2 = hp.Float('dropout_rate_2', min_value=0.3, max_value=0.5, default=0.25, step=0.1)\n",
        "  hp_dropout_3 = hp.Float('dropout_rate_3', min_value=0.3, max_value=0.5, default=0.35, step=0.1)\n",
        "  hp_reduction_type = hp.Choice('reduction_type', values=['global_avg_pooling2d', 'max_pooling2d'])\n",
        "\n",
        "  # Define the model\n",
        "  model = tf.keras.Sequential()\n",
        "  # print('input_shape: ', (hp_img_size, hp_img_size, 1))\n",
        "  # 1st set of neural network layers (Input layer)\n",
        "  model.add(Conv2D(filters=hp_filters_1, kernel_size=(hp_kernel_size,hp_kernel_size), padding='same', activation=hp_activation, input_shape = (50,50,1)))  \n",
        "  # model.add(Conv2D(filters=hp_filters_1, kernel_size=(hp_kernel_size,hp_kernel_size), padding='same', activation=hp_activation, input_shape = (hp_img_size, hp_img_size, 1)))  \n",
        "  if hp_reduction_type == 'global_avg_pooling2d':\n",
        "    model.add(GlobalAveragePooling2D(keepdims=True))\n",
        "  else:\n",
        "    model.add(MaxPooling2D(pool_size=(hp_pool_size,hp_pool_size), strides=(hp_strides,hp_strides)))  \n",
        "  # if hp.Boolean('dropout_1'):\n",
        "    # model.add(Dropout(hp_dropout_1))\n",
        "  \n",
        "  # 2nd set of neural network layers\n",
        "  # if hp.Boolean('conv_layer_2'):  \n",
        "  model.add(Conv2D(filters=hp_filters_2, kernel_size=(hp_kernel_size,hp_kernel_size), padding='same', activation=hp_activation))\n",
        "  # if hp.Boolean('BatchNormalization_1'):\n",
        "  model.add(BatchNormalization())\n",
        "  if hp_reduction_type == 'global_avg_pooling2d':\n",
        "    model.add(GlobalAveragePooling2D(keepdims=True))\n",
        "  else:\n",
        "    model.add(MaxPooling2D(pool_size=(hp_pool_size,hp_pool_size), strides=(hp_strides,hp_strides)))  \n",
        "  # if hp.Boolean('dropout_2'):\n",
        "    # model.add(Dropout(hp_dropout_1))\n",
        "\n",
        "  # 3rd set of neural network layers\n",
        "  # if hp.Boolean('conv_layer_3'):  \n",
        "  model.add(Conv2D(filters=hp_filters_3, kernel_size=(hp_kernel_size,hp_kernel_size), padding='same', activation=hp_activation.lower()))\n",
        "  # if hp.Boolean('BatchNormalization_2'):\n",
        "  model.add(BatchNormalization())\n",
        "  if hp_reduction_type == 'global_avg_pooling2d':\n",
        "    model.add(GlobalAveragePooling2D(keepdims=True))\n",
        "  else:\n",
        "    model.add(MaxPooling2D(pool_size=(hp_pool_size,hp_pool_size), strides=(hp_strides, hp_strides)))  \n",
        "  # if hp.Boolean('dropout_3'):\n",
        "  # model.add(Dropout(hp_dropout_2))\n",
        "\n",
        "  # Flatten layer\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Fully connected dense layer\n",
        "  model.add(Dense(units = hp_dense, activation = hp_activation))\n",
        "  # if hp.Boolean('BatchNormalization_3'):\n",
        "  model.add(BatchNormalization())\n",
        "  if hp.Boolean('dropout_4'):\n",
        "    model.add(Dropout(hp_dropout_3))\n",
        "  \n",
        "  # Output layer\n",
        "  model.add(Dense(units = 2, activation = 'softmax'))        # output layer\n",
        "  \n",
        "  # Define the optimizer\n",
        "  def selected_optimizer(optimizer):\n",
        "    if optimizer.lower() == 'sgd':\n",
        "        return SGD(learning_rate=hp_learning_rate)           # SGD(learning_rate=learning_rate, momentum=0.95, decay=1, nesterov=True)\n",
        "    elif optimizer.lower() == 'adam':\n",
        "        return Adam(learning_rate=hp_learning_rate)          # Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8, kappa=1-1e-8)\n",
        "    elif optimizer.lower() == 'adadelta':\n",
        "        return Adadelta(learning_rate=hp_learning_rate)      # Adadelta(learning_rate=learning_rate, rho=0.95, epsilon=1e-6)\n",
        "    elif optimizer.lower() == 'adagrad':\n",
        "        return Adagrad(learning_rate=hp_learning_rate)       # Adagrad(learning_rate=learning_rate, epsilon=1e-6)\n",
        "    elif optimizer.lower() == 'rmsprop':\n",
        "        return RMSprop(learning_rate=hp_learning_rate)       # RMSprop(learning_rate=learning_rate, rho=0.9, epsilon=1e-6)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=CategoricalCrossentropy(), \n",
        "                optimizer=selected_optimizer(hp_optimizer), \n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "-b-MQQn9Erwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, the **max_trials** variable represents the number of hyperparameter combinations that will be tested by the tuner, while the **execution_per_trial** variable is the number of models that should be built and fit for each trial for robustness purposes. The next section explains how to set them\n",
        "\n",
        "https://www.sicara.fr/blog-technique/hyperparameter-tuning-keras-tuner<br>\n",
        "https://www.kaggle.com/code/fchollet/keras-kerastuner-best-practices/notebook"
      ],
      "metadata": {
        "id": "SnHwzogJu0BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "stop_early = EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 3)\n",
        "# stop_early = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 3)\n",
        "# 1) Hyperband\n",
        "# tuner = kt.Hyperband(build_cnn,                     \n",
        "#                      objective='val_accuracy',\n",
        "#                      max_epochs=10,\n",
        "#                      factor=3,\n",
        "#                      overwrite=True,\n",
        "#                      directory='hj_dir',\n",
        "#                      project_name='breast_cancer_classification')\n",
        "# 2) RandomSearch\n",
        "tuner = kt.RandomSearch(\n",
        "          # CNN_HyperModel(),\n",
        "          build_cnn,\n",
        "          objective=\"val_accuracy\",\n",
        "          max_trials=100,                     # max_trials=50 or 10,\n",
        "          executions_per_trial=2,           # executions_per_trial=10,\n",
        "          overwrite=True,\n",
        "          directory=\"hj_dir\",\n",
        "          project_name=\"breast_cancer_classification\")\n",
        "\n",
        "tuner.search(train_data_generator, \n",
        "             epochs=10, \n",
        "             callbacks=[stop_early], \n",
        "             validation_data=validation_data_generator)"
      ],
      "metadata": {
        "id": "yH0jfZqX2Qxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_all = np.concatenate((train_data_generator, validation_data_generator))"
      ],
      "metadata": {
        "id": "4-ChFsRGFKYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.analyticsvidhya.com/blog/2020/08/image-augmentation-on-the-fly-using-keras-imagedatagenerator/"
      ],
      "metadata": {
        "id": "5L2ndY3cZWSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]     # num_trials=5\n",
        "# model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters()[0]     # num_trials=5\n",
        "model = build_cnn(best_hps)\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, classification_report\n",
        "# from sklearn import svm\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_delta=0.0001, patience=1, verbose=1)\n",
        "\n",
        "file_path = 'weights.hdf5'    # save the weights and biases\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# Fit with the entire dataset (both training and validation sets)\n",
        "\n",
        "history = model.fit(train_data_generator,\n",
        "                  epochs=10,\n",
        "                  # steps_per_epoch=len(train_data_generator)//BATCH_SIZE, \n",
        "                  callbacks=[lr_reduce, checkpoint, stop_early],\n",
        "                  validation_data = validation_data_generator)\n",
        "                  # validation_steps=len(validation_data_generator)//BATCH_SIZE)\n",
        "# history = model.fit_generator(train_data_generator.flow(train_data_generator, batch_size=BATCH_SIZE),\n",
        "#                   steps_per_epoch = train_generator.shape[0] / BATCH_SIZE,\n",
        "#                   epochs=60,\n",
        "#                   callbacks=[lr_reduce, checkpoint, stop_early],\n",
        "#                   validation_data = validation_data_generator)\n",
        "# history = model.fit_generator(train_data_generator,\n",
        "#                   epochs=60,\n",
        "#                   callbacks=[lr_reduce, checkpoint, stop_early],\n",
        "#                   validation_data = validation_data_generator).decision_function(test_data_generator)\n",
        "# pd.DataFrame(history.history)\n",
        "\n",
        "# Plot loss and accuracy of best model on every epoch\n",
        "hist = history.history\n",
        "x_arr = np.arange(len(hist['loss'])) + 1\n",
        "\n",
        "fig = plt.figure(figsize=(16,6))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "ax.plot(x_arr, hist['loss'], '-o', label='Train Loss')\n",
        "ax.plot(x_arr, hist['val_loss'], '--<', label='Validation Loss')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Loss', size=14)\n",
        "ax.set_title('Loss', size=20)\n",
        "\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "ax.plot(x_arr, hist['accuracy'], '-o', label='Train Acc.')\n",
        "ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation Acc.')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Accuracy', size=14)\n",
        "ax.set_title('Accuracy', size=20);\n",
        "\n",
        "test_accuracy = round(model.evaluate(test_data_generator, verbose=0,\n",
        "                          return_dict=True)['accuracy'], 2)\n",
        "training_accuracy = round(history.history['accuracy'][-1], 2)\n",
        "val_accuracy = round(history.history['val_accuracy'][-1], 2)\n",
        "count_params = model.count_params()\n",
        "model_summary = pd.DataFrame({'test_acc':test_accuracy,\n",
        "                              'training_acc': training_accuracy,\n",
        "                              'val_acc': val_accuracy,\n",
        "                              'num_params':  f'{count_params:,}'}, index=[0]) \n",
        "\n",
        "print(model.summary())\n",
        "model_summary"
      ],
      "metadata": {
        "id": "iAgUf5GbSBbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the hyperparameter values of top 2 models \n",
        "tuner.results_summary(1)"
      ],
      "metadata": {
        "id": "zTTakeLM0-PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, classification_report\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "\n",
        "def error_analysis(model_name, model, test_labels, test_data_generator):\n",
        "  num_of_test_samples = len(test_labels)\n",
        "  classes = ['Non-IDC(0)','IDC(1)']\n",
        "\n",
        "  y_true = test_data_generator.classes\n",
        "  y_pred = model.predict_generator(test_data_generator, num_of_test_samples // BATCH_SIZE + 1)    # probabilities\n",
        "  y_pred_argmax = np.argmax(y_pred, axis=1)                      # 0s and 1s: return the indicies of the max values along the axis (axis=1: each row)   TODO: look into prob threshold\n",
        "\n",
        "\n",
        "  # Confusion matrix  \n",
        "  conf_max = confusion_matrix(y_true, y_pred_argmax)             # conf.max should use 0s and 1s for y_pred\n",
        "  perf_conf_max = conf_max.astype('float')/conf_max.sum(axis=1)[:np.newaxis]*100\n",
        "  df_perf_conf_max = pd.DataFrame(perf_conf_max, index=classes, columns=classes)\n",
        "\n",
        "  plt.figure(figsize=(6,5))\n",
        "  sns.heatmap(df_perf_conf_max, annot=True, cmap='coolwarm', annot_kws={'fontsize':16}, linewidth=0.5, fmt='.0f')  \n",
        "  plt.xlabel('Predicted Label', fontsize=14)\n",
        "  plt.ylabel('True Label', fontsize=14)\n",
        "  plt.title('Confusion Matrix (%)', fontsize=15)\n",
        "  \n",
        "  # Classification report (classification_report should use 0s and 1s for y_pred)\n",
        "  print('=============== Classification Report ===============\\n\\n', classification_report(y_true, y_pred_argmax, target_names=['Non-IDC', 'IDC']), '\\n=====================================================\\n')\n",
        "  \n",
        "  # Cross validation score\n",
        "  # cv = ShuffleSplit(n_splits=100, test_size=.25, random_state=0)\n",
        "  # cv_score = np.median(cross_val_score(model, y_true, y_pred, cv=cv))*100\n",
        "  # print('cv_score = ',cv_score)\n",
        "\n",
        "  # Precision, recall, and f1_score\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred_argmax).ravel()     # np.ravel(): returns contiguous flattened array (1D array with all the input-array elements and with the same type as it)\n",
        "  accuracy = round(accuracy_score(y_true, y_pred_argmax), 2)\n",
        "  precision = round(precision_score(y_true, y_pred_argmax), 2)\n",
        "  recall = round(recall_score(y_true, y_pred_argmax), 2)\n",
        "  f1score = round((2*precision*recall)/(precision+recall), 2)\n",
        "  error_rate = round(1-accuracy, 2)\n",
        "\n",
        "  # cohen_kappa score and zero_one loss\n",
        "  cohen_kappa = round(cohen_kappa_score(y_true, y_pred_argmax), 2)\n",
        "  zo_loss = round(zero_one_loss(y_true, y_pred_argmax), 2)\n",
        "\n",
        "  # Area under the ROC curve\n",
        "  roc_log = roc_auc_score(y_true, y_pred[:,1], multi_class='ovr')   # for the roc curve, we need to use a vector of probabilities so just chose one column and all rows\n",
        "  fpr, tpr, threshold = roc_curve(y_true, y_pred[:,1])\n",
        "  area_under_curve = round(auc(fpr, tpr), 2)  \n",
        "\n",
        "  plt.figure(figsize=(6,5))\n",
        "  plt.plot([0, 1], [0, 1], 'r--')  \n",
        "  plt.plot(fpr, tpr, label='ROC-AUC = {:.2f}'.format(area_under_curve))  \n",
        "  plt.xlabel('False positive rate', fontsize=14)\n",
        "  plt.ylabel('True positive rate', fontsize=14)\n",
        "  plt.title('ROC Curve', fontsize=18)\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  model_summary = pd.DataFrame({'Model':model_name,\n",
        "                                'Accuracy': accuracy,\n",
        "                                'Precision': precision,\n",
        "                                'Recall': recall,\n",
        "                                'F1_score': f1score,\n",
        "                                'Error Rate': error_rate,\n",
        "                                'ROC-AUC score': area_under_curve,\n",
        "                                'Cohen Kappa': cohen_kappa,\n",
        "                                'Zero-One Loss': zo_loss}, index=[0]) \n",
        "  return model_summary\n",
        "  \n",
        "error_analysis('CNN', model, test_labels, test_data_generator)"
      ],
      "metadata": {
        "id": "55uBtQIKC7fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # plot my model architecture\n",
        "# tf.keras.utils.plot_model(\n",
        "#     model,\n",
        "#     show_shapes=True,\n",
        "#     show_layer_names=False,\n",
        "#     show_layer_activations=True,\n",
        "# )"
      ],
      "metadata": {
        "id": "bTqd7IJeTaVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cufflinks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pRgWBFBSV5q",
        "outputId": "d2d931dc-d96c-45df-af3c-9fa1b3aeaf7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cufflinks in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: plotly>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from cufflinks) (1.21.6)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks) (0.3.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks) (7.7.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from cufflinks) (1.3.5)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks) (57.4.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks) (7.9.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->cufflinks) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->cufflinks) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->cufflinks) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->cufflinks) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->cufflinks) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->cufflinks) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->cufflinks) (4.4.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->cufflinks) (3.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->cufflinks) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->cufflinks) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->cufflinks) (3.0.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.0.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.3.0->cufflinks) (0.8.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->cufflinks) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->cufflinks) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.1.1->cufflinks) (8.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.3.0->cufflinks) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (5.7.16)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (4.11.2)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (1.8.0)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (2.11.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.15.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (5.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<=3.0.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (5.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.8.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (2.16.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (4.13.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (4.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (3.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.19.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks) (0.5.1)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "labels=['IDC Malignant', 'IDC Benign']\n",
        "values = [78786, 198738]\n",
        "colors = ['#f5b3ae','#c3f3fa']\n",
        "\n",
        "fig = make_subplots(1,1, specs=[[{'type':'domain'}]],\n",
        "                   subplot_titles=[''])\n",
        "fig.add_trace(go.Pie(labels=labels, values=values, textinfo='label+percent', pull=[0.1, 0], scalegroup='one', marker_colors=colors,\n",
        "                    name='data_split'), 1,1)\n",
        "\n",
        "\n",
        "fig.update_layout(title_text='Data Split Before Sampling')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Xg1BCUW7Q70U",
        "outputId": "a6ddcb39-33d4-47b3-adf2-573515ccf44d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9b38c8e2-d664-4146-9b17-0fcdc3338f05\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9b38c8e2-d664-4146-9b17-0fcdc3338f05\")) {                    Plotly.newPlot(                        \"9b38c8e2-d664-4146-9b17-0fcdc3338f05\",                        [{\"labels\":[\"IDC Malignant\",\"IDC Benign\"],\"marker\":{\"colors\":[\"#f5b3ae\",\"#c3f3fa\"]},\"name\":\"data_split\",\"pull\":[0.1,0],\"scalegroup\":\"one\",\"textinfo\":\"label+percent\",\"values\":[78786,198738],\"type\":\"pie\",\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]}}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Data Split Before Sampling\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9b38c8e2-d664-4146-9b17-0fcdc3338f05');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XuRbO-ntQ7bP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}